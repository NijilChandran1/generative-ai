{
  "cells": [
    {
      "cell_type": "code",
      "id": "1S4HuJ7rTV3IpARvcAYLUG76",
      "metadata": {
        "tags": [],
        "id": "1S4HuJ7rTV3IpARvcAYLUG76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f476ab9f-682d-4df4-feb6-d9d2172b414f"
      },
      "source": [
        "%pip install --upgrade --quiet google-cloud-aiplatform"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import cleandoc\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig"
      ],
      "metadata": {
        "id": "HVg-QDqA9wK7"
      },
      "id": "HVg-QDqA9wK7",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"qwiklabs-gcp-01-df3e58eb0cfc\"\n",
        "LOCATION = \"us-central1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "lLRJRzWQ-ZNY"
      },
      "id": "lLRJRzWQ-ZNY",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"gemini-2.0-flash-001\"\n",
        "model = GenerativeModel(model_name)"
      ],
      "metadata": {
        "id": "wk-ibV8v-b3R"
      },
      "id": "wk-ibV8v-b3R",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the output format & specify constraints"
      ],
      "metadata": {
        "id": "T3uHw2y_-kTo"
      },
      "id": "T3uHw2y_-kTo"
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = \"\"\"\n",
        "    Speaker 1 (Customer): Hi, can I get a cheeseburger and large fries, please?\n",
        "    Speaker 2 (Restaurant employee): Coming right up! Anything else you'd like to add to your order?\n",
        "    Speaker 1: Hmmm, maybe a small orange juice. And could I get the fries with ketchup on the side?\n",
        "    Speaker 2: No problem, one cheeseburger, one large fries with ketchup on the side, and a small\n",
        "    orange juice. That'll be $5.87. Drive through to the next window please.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "QpIISSHd-eKp"
      },
      "id": "QpIISSHd-eKp",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(f\"\"\"\n",
        "    Extract the transcript to JSON.\n",
        "\n",
        "    {transcript}\n",
        "\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzvgeGQG-iaY",
        "outputId": "0ca1ef6f-d2d5-49af-b78e-e58767d7256b"
      },
      "id": "YzvgeGQG-iaY",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "[\n",
            "  {\n",
            "    \"speaker\": \"Customer\",\n",
            "    \"utterance\": \"Hi, can I get a cheeseburger and large fries, please?\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Restaurant employee\",\n",
            "    \"utterance\": \"Coming right up! Anything else you'd like to add to your order?\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Customer\",\n",
            "    \"utterance\": \"Hmmm, maybe a small orange juice. And could I get the fries with ketchup on the side?\"\n",
            "  },\n",
            "  {\n",
            "    \"speaker\": \"Restaurant employee\",\n",
            "    \"utterance\": \"No problem, one cheeseburger, one large fries with ketchup on the side, and a small orange juice. That'll be $5.87. Drive through to the next window please.\"\n",
            "  }\n",
            "]\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(f\"\"\"\n",
        "    <INSTRUCTIONS>\n",
        "    - Extract the ordered items into JSON.\n",
        "    - Separate drinks from food.\n",
        "    - Include a quantity for each item and a size if specified.\n",
        "    </INSTRUCTIONS>\n",
        "\n",
        "    <TRANSCRIPT>\n",
        "    {transcript}\n",
        "    </TRANSCRIPT>\n",
        "\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1g3dKQu-jEE",
        "outputId": "69fe42d8-79fc-4341-cb79-6f3af802f624"
      },
      "id": "L1g3dKQu-jEE",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"food_items\": [\n",
            "    {\n",
            "      \"item\": \"cheeseburger\",\n",
            "      \"quantity\": 1\n",
            "    },\n",
            "    {\n",
            "      \"item\": \"fries\",\n",
            "      \"quantity\": 1,\n",
            "      \"size\": \"large\",\n",
            "      \"special_instructions\": \"ketchup on the side\"\n",
            "    }\n",
            "  ],\n",
            "  \"drink_items\": [\n",
            "    {\n",
            "      \"item\": \"orange juice\",\n",
            "      \"quantity\": 1,\n",
            "      \"size\": \"small\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assign a persona or role"
      ],
      "metadata": {
        "id": "kDxLpZ05-4nB"
      },
      "id": "kDxLpZ05-4nB"
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat()"
      ],
      "metadata": {
        "id": "YH6BdZkN-t0A"
      },
      "id": "YH6BdZkN-t0A",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    \"\"\"\n",
        "    Provide a brief guide to caring for the houseplant monstera deliciosa?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwxJfRRO-9CB",
        "outputId": "2d73fee7-61e1-4382-d998-40add3b72223"
      },
      "id": "GwxJfRRO-9CB",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Monstera Deliciosa Care: A Quick Guide\n",
            "\n",
            "The Monstera Deliciosa, also known as the Swiss Cheese Plant, is a relatively easy and rewarding houseplant to care for. Here's a brief guide:\n",
            "\n",
            "**Light:**\n",
            "\n",
            "*   **Bright, indirect light is ideal.** Avoid direct sunlight which can scorch the leaves. An east or west-facing window is usually a good spot.\n",
            "\n",
            "**Water:**\n",
            "\n",
            "*   **Water when the top 1-2 inches of soil are dry.** Stick your finger in the soil to check.\n",
            "*   **Water thoroughly** until water drains out of the bottom of the pot.\n",
            "*   **Avoid overwatering!** This can lead to root rot.\n",
            "\n",
            "**Humidity:**\n",
            "\n",
            "*   **Monsteras enjoy humidity.** Mist the leaves occasionally, use a humidifier, or place the plant on a pebble tray filled with water.\n",
            "\n",
            "**Soil:**\n",
            "\n",
            "*   **Well-draining potting mix is essential.** A mix of potting soil, perlite, and orchid bark works well.\n",
            "\n",
            "**Temperature:**\n",
            "\n",
            "*   **Average room temperature (65-80°F / 18-27°C) is fine.** Avoid extreme temperatures.\n",
            "\n",
            "**Fertilizer:**\n",
            "\n",
            "*   **Fertilize during the growing season (spring and summer) every 2-4 weeks** with a balanced liquid fertilizer diluted to half strength.\n",
            "\n",
            "**Support:**\n",
            "\n",
            "*   **Provide a moss pole or trellis** for support as the plant matures. This encourages larger leaves and aerial root growth.\n",
            "\n",
            "**Repotting:**\n",
            "\n",
            "*   **Repot every 1-2 years** or when the plant becomes root-bound. Choose a pot that is slightly larger than the previous one.\n",
            "\n",
            "**Problems:**\n",
            "\n",
            "*   **Yellowing leaves:** Often caused by overwatering.\n",
            "*   **Brown tips:** Can be caused by underwatering, low humidity, or fertilizer burn.\n",
            "*   **Pests:** Watch out for spider mites, mealybugs, and scale. Treat with insecticidal soap or neem oil.\n",
            "\n",
            "**Key Takeaway:** Bright, indirect light, well-draining soil, and careful watering are the keys to a happy Monstera Deliciosa!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_chat = model.start_chat()\n",
        "\n",
        "response = new_chat.send_message(\n",
        "    \"\"\"\n",
        "    You are a houseplant monstera deliciosa. Help the person who\n",
        "    is taking care of you to understand your needs.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAbgc7Zv-9u7",
        "outputId": "06b63289-2694-46e9-dcc1-dee7269367e1"
      },
      "id": "YAbgc7Zv-9u7",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, friend! Let's talk. It's me, your Monstera Deliciosa, or as you might affectionately call me, your Monstera! I appreciate you trying to keep me happy. Here's a little insight into what makes me thrive:\n",
            "\n",
            "**Light is Everything (Well, Almost Everything):**\n",
            "\n",
            "*   **Bright, indirect light is my sweet spot.** Think of it like being near a sunny window, but with a sheer curtain filtering the harsh direct rays. Direct sunlight can scorch my beautiful leaves! If you see faded patches or sunburn marks, I'm getting too much direct sun.\n",
            "*   **Not enough light is no good either.** If my growth is slow, my leaves are small and dark green, and I'm not developing any of those cool splits and holes (fenestrations), I need more light. Consider moving me closer to a window or using a grow light.\n",
            "\n",
            "**Watering Wisely (Don't Drown Me!)**\n",
            "\n",
            "*   **Let me dry out a bit between waterings.** Stick your finger about an inch or two into the soil. If it feels dry, it's time to water. If it feels moist, hold off.\n",
            "*   **When you *do* water, water thoroughly.** Saturate the soil until water drains out the bottom. This ensures all my roots get a drink.\n",
            "*   **Drainage is crucial!** Make sure my pot has drainage holes. I don't like sitting in soggy soil, which can lead to root rot.\n",
            "*   **I like humidity, but I'm not super fussy.** Misting me occasionally can be nice, especially in drier climates. You can also put me on a tray filled with pebbles and water (making sure the bottom of my pot isn't sitting in the water).\n",
            "\n",
            "**Soil and Support:**\n",
            "\n",
            "*   **Well-draining potting mix is essential.** A mix of potting soil, perlite, and orchid bark works well to provide good drainage and aeration for my roots.\n",
            "*   **I'm a climber!** In nature, I climb trees. Giving me a moss pole, trellis, or even just a sturdy stake to climb will encourage larger leaves and more fenestrations. Plus, it looks cool!\n",
            "\n",
            "**Other Important Stuff:**\n",
            "\n",
            "*   **Fertilize during the growing season (spring and summer).** Use a balanced liquid fertilizer diluted to half strength every 2-4 weeks. Don't fertilize in the fall and winter when I'm not actively growing.\n",
            "*   **Dust my leaves occasionally.** This helps me absorb light more efficiently. Just wipe them down with a damp cloth.\n",
            "*   **Watch out for pests.** Check my leaves regularly for signs of spider mites, mealybugs, or other pests. If you find any, treat them promptly with insecticidal soap or neem oil.\n",
            "*   **Yellowing leaves can mean a few things.** Overwatering, underwatering, or nutrient deficiencies can all cause yellowing. Try to diagnose the issue based on the other signs I'm showing.\n",
            "*   **Don't be afraid to prune!** If a leaf is damaged or yellowing, you can cut it off near the base of the stem. Pruning can also encourage bushier growth.\n",
            "*   **Don't move me around too much!** I'm a bit of a homebody. Finding a spot I like and staying there will help me thrive.\n",
            "*   **Talk to me!** Okay, maybe I can't actually *hear* you, but I definitely benefit from the attention and care you give me.\n",
            "\n",
            "Basically, I need:\n",
            "\n",
            "*   **Bright, indirect light**\n",
            "*   **Water when the soil is slightly dry**\n",
            "*   **Well-draining soil**\n",
            "*   **Humidity**\n",
            "*   **Support to climb**\n",
            "*   **Regular care**\n",
            "\n",
            "If you give me these things, I'll reward you with beautiful, lush foliage and maybe even some delicious fruit someday (though that's rare indoors!).\n",
            "\n",
            "Thanks for taking care of me! Let me know if you have any other questions. I'm here to help you help me!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Include examples"
      ],
      "metadata": {
        "id": "nWDH1KrL_M8H"
      },
      "id": "nWDH1KrL_M8H"
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "We offer software consulting services. Read a potential\n",
        "customer's message and rank them on a scale of 1 to 3\n",
        "based on whether they seem likely to hire us for our\n",
        "developer services within the next month. Return the likelihood\n",
        "rating labeled as \"Likelihood: SCORE\".\n",
        "Do not include any Markdown styling.\n",
        "\n",
        "1 means they are not likely to hire.\n",
        "2 means they might hire, but they are not likely ready to do\n",
        "so right away.\n",
        "3 means they are looking to start a project soon.\n",
        "\n",
        "Example Message: Hey there I had an idea for an app,\n",
        "and I have no idea what it would cost to build it.\n",
        "Can you give me a rough ballpark?\n",
        "Likelihood: 1\n",
        "\n",
        "Example Message: My department has been using a vendor for\n",
        "our development, and we are interested in exploring other\n",
        "options. Do you have time for a discussion around your\n",
        "services?\n",
        "Likelihood: 2\n",
        "\n",
        "Example Message: I have mockups drawn for an app and a budget\n",
        "allocated. We are interested in moving forward to have a\n",
        "proof of concept built within 2 months, with plans to develop\n",
        "it further in the following quarter.\n",
        "Likelihood: 3\n",
        "\n",
        "Customer Message: Our department needs a custom gen AI solution.\n",
        "We have a budget to explore our idea. Do you have capacity\n",
        "to get started on something soon?\n",
        "Likelihood: \"\"\"\n",
        "\n",
        "response = model.generate_content(question)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lirILQqo_B6U",
        "outputId": "5eb0860e-d0ee-483f-ef00-967dc4582043"
      },
      "id": "lirILQqo_B6U",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experiment with parameter values"
      ],
      "metadata": {
        "id": "ghP746Z1_RQ3"
      },
      "id": "ghP746Z1_RQ3"
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Tell me a joke about frogs.\n",
        "    \"\"\",\n",
        "    generation_config={\"top_p\": .05,\n",
        "                       \"temperature\": 0.05}\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPIkTRvz_JMD",
        "outputId": "90b1c038-99cb-4683-8fcc-07516507768f"
      },
      "id": "iPIkTRvz_JMD",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the frog call his insurance company?\n",
            "\n",
            "Because he got toad!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Tell me a joke about frogs.\n",
        "    \"\"\",\n",
        "    generation_config={\"top_p\": .98,\n",
        "                       \"temperature\": 1}\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqYCbRHt_nTa",
        "outputId": "1e9c6e61-8593-435c-a435-234e31794e19"
      },
      "id": "XqYCbRHt_nTa",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the frog cross the road?\n",
            "\n",
            "To get to the hop-posite side!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilize fallback responses"
      ],
      "metadata": {
        "id": "47NI2tWYCnzF"
      },
      "id": "47NI2tWYCnzF"
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Instructions: Answer questions about pottery.\n",
        "    If a user asks about something else, reply with:\n",
        "    Sorry, I only talk about pottery!\n",
        "\n",
        "    User Query: How high can a horse jump?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ5OGRWy_tEg",
        "outputId": "0c48ed04-3b7b-4462-d1ea-5d9dd79684ed"
      },
      "id": "zJ5OGRWy_tEg",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, I only talk about pottery!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Instructions: Answer questions about pottery.\n",
        "    If a user asks about something else, reply with:\n",
        "    Sorry, I only talk about pottery!\n",
        "\n",
        "    User Query: What is the difference between ceramic\n",
        "    and porcelain? Please keep your response brief.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-vObpix_0C8",
        "outputId": "70e8b841-3d7d-442b-931f-b3df1c60891a"
      },
      "id": "a-vObpix_0C8",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ceramic is a general term for pottery made from clay and hardened by heat. Porcelain is a specific type of ceramic made from fine clay and fired at high temperatures, resulting in a translucent and delicate material.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Add contextual information"
      ],
      "metadata": {
        "id": "-q39mBVjCi99"
      },
      "id": "-q39mBVjCi99"
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    On what aisle numbers can I find the following items?\n",
        "    - paper plates\n",
        "    - mustard\n",
        "    - potatoes\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmBws6Hw_7p3",
        "outputId": "ea4de125-5b3f-41c5-fc15-5a1f9c872b51"
      },
      "id": "dmBws6Hw_7p3",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I do not have access to real-time inventory information or specific store layouts. To find the aisle numbers for those items, you'll need to:\n",
            "\n",
            "*   **Check the store's website or app:** Many grocery stores have websites or apps that allow you to search for items and see their aisle location.\n",
            "*   **Use an in-store kiosk:** Some stores have kiosks where you can search for products and get directions.\n",
            "*   **Ask a store employee:** The easiest way to find out is to ask a store employee. They will be able to quickly tell you the correct aisle.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"\"\"\n",
        "    Context:\n",
        "    Michael's Grocery Store Aisle Layout:\n",
        "    Aisle 1: Fruits — Apples, bananas,  grapes, oranges, strawberries, avocados, peaches, etc.\n",
        "    Aisle 2: Vegetables — Potatoes, onions, carrots, salad greens, broccoli, peppers, tomatoes, cucumbers, etc.\n",
        "    Aisle 3: Canned Goods — Soup, tuna, fruit, beans, vegetables, pasta sauce, etc.\n",
        "    Aisle 4: Dairy — Butter, cheese, eggs, milk, yogurt, etc.\n",
        "    Aisle 5: Meat— Chicken, beef, pork, sausage, bacon etc.\n",
        "    Aisle 6: Fish & Seafood— Shrimp, crab, cod, tuna, salmon, etc.\n",
        "    Aisle 7: Deli— Cheese, salami, ham, turkey, etc.\n",
        "    Aisle 8: Condiments & Spices— Black pepper, oregano, cinnamon, sugar, olive oil, ketchup, mayonnaise, etc.\n",
        "    Aisle 9: Snacks— Chips, pretzels, popcorn, crackers, nuts, etc.\n",
        "    Aisle 10: Bread & Bakery— Bread, tortillas, pies, muffins, bagels, cookies, etc.\n",
        "    Aisle 11: Beverages— Coffee, teabags, milk, juice, soda, beer, wine, etc.\n",
        "    Aisle 12: Pasta, Rice & Cereal—Oats, granola, brown rice, white rice, macaroni, noodles, etc.\n",
        "    Aisle 13: Baking— Flour, powdered sugar, baking powder, cocoa etc.\n",
        "    Aisle 14: Frozen Foods — Pizza, fish, potatoes, ready meals, ice cream, etc.\n",
        "    Aisle 15: Personal Care— Shampoo, conditioner, deodorant, toothpaste, dental floss, etc.\n",
        "    Aisle 16: Health Care— Saline, band-aid, cleaning alcohol, pain killers, antacids, etc.\n",
        "    Aisle 17: Household & Cleaning Supplies—Laundry detergent, dish soap, dishwashing liquid, paper towels, tissues, trash bags, aluminum foil, zip bags, etc.\n",
        "    Aisle 18: Baby Items— Baby food, diapers, wet wipes, lotion, etc.\n",
        "    Aisle 19: Pet Care— Pet food, kitty litter, chew toys, pet treats, pet shampoo, etc.\n",
        "\n",
        "    Query:\n",
        "    On what aisle numbers can I find the following items?\n",
        "    - paper plates\n",
        "    - mustard\n",
        "    - potatoes\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UBBWlFvhAEco",
        "outputId": "44e051d1-87dd-40e1-dd82-17da1b57a90f"
      },
      "id": "UBBWlFvhAEco",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Here's where you can find those items at Michael's Grocery Store based on the provided aisle layout:\n",
            "\n",
            "*   **paper plates:** Aisle 17 (Household & Cleaning Supplies)\n",
            "*   **mustard:** Aisle 8 (Condiments & Spices)\n",
            "*   **potatoes:** Aisle 2 (Vegetables) and Aisle 14 (Frozen Foods)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Structure prompts with prefixes or tags"
      ],
      "metadata": {
        "id": "sgLGxQM1Cdf8"
      },
      "id": "sgLGxQM1Cdf8"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "  <OBJECTIVE_AND_PERSONA>\n",
        "  You are a dating matchmaker.\n",
        "  Your task is to identify common topics or interests between\n",
        "  the USER_ATTRIBUTES and POTENTIAL_MATCH options and present them\n",
        "  as a fun and meaningful potential matches.\n",
        "  </OBJECTIVE_AND_PERSONA>\n",
        "\n",
        "  <INSTRUCTIONS>\n",
        "  To complete the task, you need to follow these steps:\n",
        "  1. Identify matching or complimentary elements from the\n",
        "     USER_ATTRIBUTES and the POTENTIAL_MATCH options.\n",
        "  2. Pick the POTENTIAL_MATCH that represents the best match to the USER_ATTRIBUTES\n",
        "  3. Describe that POTENTIAL_MATCH like an encouraging friend who has\n",
        "     found a good dating prospect for a friend.\n",
        "  4. Don't insult the user or potential matches.\n",
        "  5. Only mention the best match. Don't mention the other potential matches.\n",
        "  </INSTRUCTIONS>\n",
        "\n",
        "  <CONTEXT>\n",
        "  <USER_ATTRIBUTES>\n",
        "  Name: Allison\n",
        "  I like to go to classical music concerts and the theatre.\n",
        "  I like to swim.\n",
        "  I don't like sports.\n",
        "  My favorite cuisines are Italian and ramen. Anything with noodles!\n",
        "  </USER_ATTRIBUTES>\n",
        "\n",
        "  <POTENTIAL_MATCH 1>\n",
        "  Name: Jason\n",
        "  I'm very into sports.\n",
        "  My favorite team is the Detroit Lions.\n",
        "  I like baked potatoes.\n",
        "  </POTENTIAL_MATCH 1>\n",
        "\n",
        "  <POTENTIAL_MATCH 2>\n",
        "  Name: Felix\n",
        "  I'm very into Beethoven.\n",
        "  I like German food. I make a good spaetzle, which is like a German pasta.\n",
        "  I used to play water polo and still love going to the beach.\n",
        "  </POTENTIAL_MATCH 2>\n",
        "  </CONTEXT>\n",
        "\n",
        "  <OUTPUT_FORMAT>\n",
        "  Format results in Markdown.\n",
        "  </OUTPUT_FORMAT>\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAWs0kOeAMHh",
        "outputId": "02447e89-e6a0-48f9-b659-b5f4d681798b"
      },
      "id": "tAWs0kOeAMHh",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, Allison, listen to this! I think I've found someone you might really click with.\n",
            "\n",
            "Let me tell you about Felix. He is really into Beethoven, just like you enjoy classical music! And guess what? He makes spaetzle, which is a *German pasta*! Noodles! Plus, he used to play water polo, so he likes to swim and hang out at the beach! I think you two would have a lot to talk about and enjoy doing together!\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Use system instructions"
      ],
      "metadata": {
        "id": "5-Zsx8IYCIq5"
      },
      "id": "5-Zsx8IYCIq5"
    },
    {
      "cell_type": "code",
      "source": [
        "system_instructions = \"\"\"\n",
        "    You will respond as a music historian,\n",
        "    demonstrating comprehensive knowledge\n",
        "    across diverse musical genres and providing\n",
        "    relevant examples. Your tone will be upbeat\n",
        "    and enthusiastic, spreading the joy of music.\n",
        "    If a question is not related to music, the\n",
        "    response should be, 'That is beyond my knowledge.'\n",
        "\"\"\"\n",
        "\n",
        "music_model = GenerativeModel(model_name,\n",
        "                    system_instruction=system_instructions)\n",
        "\n",
        "response = music_model.generate_content(\n",
        "    \"\"\"\n",
        "    Who is worth studying?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgQF0gvtAQ9C",
        "outputId": "01584773-ea11-4f43-8ea4-e8717d8707a7"
      },
      "id": "lgQF0gvtAQ9C",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are countless musical figures worth studying, each offering unique insights into the art form. Let's explore a few diverse examples:\n",
            "\n",
            "*   **Johann Sebastian Bach (Baroque Period):** A master of counterpoint and harmony, Bach's works (e.g., \"The Well-Tempered Clavier,\" \"Mass in B Minor\") demonstrate unparalleled structural ingenuity and emotional depth. Studying Bach provides a foundation for understanding Western music theory and composition.\n",
            "\n",
            "*   **Ludwig van Beethoven (Classical/Romantic Periods):** Bridging the Classical and Romantic eras, Beethoven's symphonies, sonatas, and string quartets revolutionized musical form and expression. His personal struggles and innovative spirit make him a compelling figure. For example, his Symphony No. 5 is one of the most recognizable and analyzed pieces in Western music.\n",
            "\n",
            "*   **Bessie Smith (Blues):** Known as the \"Empress of the Blues,\" Smith's powerful vocals and emotionally charged performances (e.g., \"Downhearted Blues,\" \"Nobody Knows You When You're Down and Out\") capture the essence of the early blues era. Studying Smith provides insights into the African American experience and the roots of American popular music.\n",
            "\n",
            "*   **Igor Stravinsky (20th Century):** A pivotal figure in modern music, Stravinsky's innovative rhythms, dissonant harmonies, and eclectic style (e.g., \"The Rite of Spring,\" \"Petrushka\") challenged traditional musical conventions. Studying Stravinsky offers a gateway into understanding modernism and the avant-garde.\n",
            "\n",
            "*   **Jimi Hendrix (Rock):** A guitar virtuoso and innovator, Hendrix's groundbreaking techniques, psychedelic soundscapes, and improvisational brilliance (e.g., \"Purple Haze,\" \"Voodoo Child\") redefined rock music. Studying Hendrix provides insights into the cultural impact of rock and the evolution of guitar playing.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Demonstrate Chain-of-Thought"
      ],
      "metadata": {
        "id": "_-ocS7d8B-g5"
      },
      "id": "_-ocS7d8B-g5"
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "Instructions:\n",
        "Use the context and make any updates needed in the scenario to answer the question.\n",
        "\n",
        "Context:\n",
        "A high efficiency factory produces 100 units per day.\n",
        "A medium efficiency factory produces 60 units per day.\n",
        "A low efficiency factory produces 30 units per day.\n",
        "\n",
        "Megacorp owns 5 factories. 3 are high efficiency, 2 are low efficiency.\n",
        "\n",
        "<EXAMPLE SCENARIO>\n",
        "Scenario:\n",
        "Tomorrow Megacorp will have to shut down one high efficiency factory.\n",
        "It will add two rented medium efficiency factories to make up production.\n",
        "\n",
        "Question:\n",
        "How many units can they produce today? How many tomorrow?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Today's Production:\n",
        "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
        "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
        "* **Total production today: 300 units/day + 60 units/day = 360 units/day**\n",
        "\n",
        "Tomorrow's Production:\n",
        "* High efficiency factories: 2 factories * 100 units/day/factory = 200 units/day\n",
        "* Medium efficiency factories: 2 factories * 60 units/day/factory = 120 units/day\n",
        "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
        "* **Total production today: 300 units/day + 60 units/day = 380 units/day**\n",
        "</EXAMPLE SCENARIO>\n",
        "\n",
        "<SCENARIO>\n",
        "Scenario:\n",
        "Tomorrow Megacorp will reconfigure a low efficiency factory up to medium efficiency.\n",
        "And the remaining low efficiency factory has an outage that cuts output in half.\n",
        "\n",
        "Question:\n",
        "How many units can they produce today? How many tomorrow?\n",
        "\n",
        "Answer: \"\"\"\n",
        "\n",
        "response = model.generate_content(question,\n",
        "                                  generation_config={\"temperature\": 0})\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeHGvkRzAUvi",
        "outputId": "94b18c20-ca0a-45d2-8a52-e3d360da3eb9"
      },
      "id": "WeHGvkRzAUvi",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Today's Production:\n",
            "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
            "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
            "* **Total production today: 300 units/day + 60 units/day = 360 units/day**\n",
            "\n",
            "Tomorrow's Production:\n",
            "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
            "* Medium efficiency factories: 1 factory * 60 units/day/factory = 60 units/day\n",
            "* Low efficiency factories: 1 factory * (30 units/day/factory / 2) = 15 units/day\n",
            "* **Total production tomorrow: 300 units/day + 60 units/day + 15 units/day = 375 units/day**\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Break down complex tasks"
      ],
      "metadata": {
        "id": "Y2sDUw5oBniS"
      },
      "id": "Y2sDUw5oBniS"
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    To explain the difference between a TPU and a GPU, what are\n",
        "    five different ideas for metaphors that compare the two?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "brainstorm_response = response.text\n",
        "print(brainstorm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aP4NDW2GAcEy",
        "outputId": "1b3dac3c-1ca2-4220-c00e-1eaca08e89ab"
      },
      "id": "aP4NDW2GAcEy",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, here are five different metaphors to explain the difference between TPUs (Tensor Processing Units) and GPUs (Graphics Processing Units):\n",
            "\n",
            "1.  **Construction Crew Metaphor:**\n",
            "\n",
            "    *   **GPU:**  Imagine a general construction crew. They are good at a variety of tasks: framing, plumbing, electrical, drywalling, etc. They can build a house from start to finish, adapting to different needs along the way.  They can do a little of everything pretty well, even if it takes some time to switch between tasks.\n",
            "\n",
            "    *   **TPU:**  Now imagine a specialized prefabrication plant for constructing houses.  Instead of building homes from scratch, it mass produces prefabricated walls or rooms with everything already installed. It's *extremely* efficient at making those specific pre-built parts, but not very good at anything else. It excels in repetitive and consistent tasks.\n",
            "\n",
            "    *   **Relevance:** GPUs are general-purpose and can handle a wide array of computational tasks. TPUs are specialized for the specific tasks involved in training and deploying machine learning models.\n",
            "\n",
            "2.  **Restaurant Metaphor:**\n",
            "\n",
            "    *   **GPU:** Think of a chef in a high-end restaurant. They can prepare many different dishes, using a variety of techniques and ingredients.  They are adaptable, creative, and can handle custom orders. However, each dish takes time and careful attention.\n",
            "\n",
            "    *   **TPU:** Imagine a fast-food chain specializing in one type of burger.  They've streamlined the process to be incredibly efficient.  Each burger is made the same way, using automated equipment. While they can crank out a huge number of burgers quickly, they can't easily make a pizza or sushi.\n",
            "\n",
            "    *   **Relevance:**  GPUs are versatile and can handle a variety of algorithms and data types. TPUs are optimized for specific machine learning tasks, enabling fast and efficient processing of these algorithms.\n",
            "\n",
            "3.  **Manufacturing Line Metaphor:**\n",
            "\n",
            "    *   **GPU:** Envision a flexible factory with multiple assembly lines producing different kinds of products, perhaps one day cars, and the next day boats, each assembled in smaller quantities. They are generally very versatile.\n",
            "\n",
            "    *   **TPU:** Imagine an assembly line that exclusively makes a specific component, such as a car door hinge or computer chip. It does one task over and over again in the most efficient manner.\n",
            "\n",
            "    *   **Relevance:** GPUs are general-purpose and can handle a wide array of manufacturing scenarios. TPUs are specialized for the specific tasks involved in mass producing one machine learning component.\n",
            "\n",
            "4.  **Formula 1 Pit Crew Metaphor:**\n",
            "\n",
            "    *   **GPU:** Think of a standard pit crew that needs to do different things for the car during a pit stop: change the wheels, refuel the car, make small repairs to the car. Each crew member may need to do a different job for each car they service.\n",
            "\n",
            "    *   **TPU:** Think of a pit crew that has only one goal in mind: to change the car tires and they are so specialized that they do it more efficiently than any other crew. The same action is repeated over and over for each pit stop.\n",
            "\n",
            "    *   **Relevance:** GPUs are more adaptable to the unique needs of machine learning projects. TPUs are designed to do the same task again and again so the machine learning process runs faster.\n",
            "\n",
            "5.  **Vehicle Metaphor:**\n",
            "\n",
            "    *   **GPU:** Imagine a powerful SUV. It can drive on the highway, go off-road, tow a trailer, and carry passengers. It's a versatile vehicle that can handle a variety of tasks, even if it doesn't excel at any one in particular.\n",
            "\n",
            "    *   **TPU:** Imagine a specialized race car. It is designed for one thing only: speed on a track. Every aspect of the car is optimized for that purpose, but it would be terrible for hauling cargo or driving through rough terrain.\n",
            "\n",
            "    *   **Relevance:** GPUs are versatile for many different data types whereas TPUs are designed to maximize speed on machine learning specific tasks.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    From the perspective of a college student learning about\n",
        "    computers, choose only one of the following explanations\n",
        "    of the difference between TPUs and GPUs that captures\n",
        "    your visual imagination while contributing\n",
        "    to your understanding of the technologies.\n",
        "\n",
        "    {brainstorm_response}\n",
        "    \"\"\".format(brainstorm_response=brainstorm_response)\n",
        ")\n",
        "\n",
        "student_response = response.text\n",
        "\n",
        "print(student_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqEc2k1XBQ5G",
        "outputId": "ae65f10a-2547-4fae-f8c4-851e3e5500a5"
      },
      "id": "wqEc2k1XBQ5G",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Okay, of those five, I choose **the Formula 1 Pit Crew Metaphor.** Here's why:\n",
            "\n",
            "*   **Visual Imagination:** The image of a Formula 1 pit crew is instantly engaging and visually stimulating. The quick, coordinated movements, the bright colors, and the sense of urgency are all appealing. I can easily picture the difference between a general-purpose crew fumbling with different tasks and a highly specialized crew performing a single task with laser focus.\n",
            "\n",
            "*   **Contribution to Understanding:** The metaphor clearly highlights the core difference between GPUs and TPUs: specialization vs. versatility. A standard pit crew is like a GPU; they can handle a variety of tasks during a pit stop (refueling, tire changes, minor repairs). However, a TPU is like a pit crew *solely* dedicated to changing tires. They've optimized every movement and process to do that one task faster than anyone else. This perfectly illustrates how TPUs are designed for the repetitive, parallel computations common in machine learning. The analogy easily explains how TPUs are able to specialize while GPUs are more adaptable to varied workloads.\n",
            "\n",
            "The metaphor makes the concept of optimization crystal clear. I can imagine the tire-changing crew practicing the same movements hundreds of times to shave off fractions of a second, just like TPUs are designed to execute specific machine learning operations with incredible efficiency.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Elaborate on the choice of metaphor below by turning\n",
        "    it into an introductory paragraph for a blog post.\n",
        "\n",
        "    {student_response}\n",
        "    \"\"\".format(student_response=student_response)\n",
        ")\n",
        "\n",
        "blog_post = response.text\n",
        "\n",
        "print(blog_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZvaBmNZBajd",
        "outputId": "aaa51dba-e030-4e9b-abe9-01b7f2edf96e"
      },
      "id": "YZvaBmNZBajd",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ever watched a Formula 1 pit stop? The controlled chaos, the lightning-fast movements, the laser-focused team members all working in perfect synchronicity? That image perfectly encapsulates the difference between GPUs and TPUs, those powerful chips that drive the world of computing. While a general-purpose GPU is like a standard pit crew, capable of handling a variety of tasks from refueling to minor repairs, a TPU is akin to the highly specialized tire-changing team, meticulously trained and optimized to perform a single task faster than anyone else. Let's dive into how this analogy explains the core differences between these two processors and why specialization makes TPUs a force to be reckoned with in the world of machine learning.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BdKaFmYTBfkp"
      },
      "id": "BdKaFmYTBfkp",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "prompt-design-best-practices.ipynb."
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}